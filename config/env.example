# Copy this file to .env in the project root and fill in your values

# LangSmith Configuration (optional but recommended)
LANGCHAIN_API_KEY=ls__your_api_key_here
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=research-agent

# Remote Model API Keys (optional - only if using remote models)
OPENAI_API_KEY=sk-your_openai_key_here
ANTHROPIC_API_KEY=sk-ant-your_anthropic_key_here
GOOGLE_API_KEY=your_google_gemini_api_key_here

# Web Search API (required for web search tool)
TAVILY_API_KEY=your_tavily_key_here
# OR use Serper API
SERPER_API_KEY=your_serper_key_here

# Model Configuration
MODEL_TYPE=local
# Options: local, openai, anthropic, gemini

# Remote Model Names (optional - used when MODEL_TYPE matches)
# OpenAI Models: gpt-4, gpt-4-turbo-preview, gpt-3.5-turbo, etc.
OPENAI_MODEL=gpt-4-turbo-preview
# Anthropic Models: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
ANTHROPIC_MODEL=claude-3-opus-20240229
# Gemini Models: gemini-flash-latest, gemini-1.5-flash, gemini-1.5-pro, gemini-pro
GEMINI_MODEL=gemini-flash-latest

# Local Model Path (if MODEL_TYPE=local)
MODEL_PATH=./models/llama-2-7b-chat.Q4_K_M.gguf
# Local model registry key (matches Streamlit dropdown)
# Options: llama-2-7b-chat-q4_k_m, meta-llama-3.1-8b-instruct-q4_k_m
LOCAL_MODEL_NAME=llama-2-7b-chat-q4_k_m

# Database Configuration
DATABASE_PATH=./data/research_agent.db

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/agent_execution.log

# Application Settings
MAX_ITERATIONS=10
TEMPERATURE=0.7

# Linode Configuration
LINODE_ROOT_PASSWORD=your_linode_root_password_here

